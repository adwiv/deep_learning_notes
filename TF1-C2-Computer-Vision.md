# Computer Vision

1. [Convolutional Neural Network](#convolutional-neural-network)
2. [Image Data Generator](#image-data-generator)
3. [Visualizing Intermediate Representation](#visualizing-intermediate-representation)
4. [Data Augmentation](#data-augmentation)
5. [Transfer learning](#transfer-learning)

## Convolutional Neural Network

CNN is generally used for images and works by applying a transformation matrix (kernel) on the original data. Using this method we can highlight the important features in the image. We can think of a ConvNet as an information disitllation pipeline wherein each layer filters out the most useful features.

The convolutional layer is followed by a pooling layer eg. `MaxPool2D`, which is designed to compress the image, while maintaining the content of the features that were highlighted by the convolution.

```python
tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')
tf.keras.layers.MaxPool2D(pool_size=(2, 2))
```

`filters` is an integer which represents the number of outputs generated by the Conv2D layer. `kernel_size` is size of the matrix that is applied on the image to highlight features. It can be an integer or a tuple like (2,3). The `pool_size` is a tuple that defines the number of pixels to pool together.

## Image Data Generator

Image Data Generator automatically labels the images according to the directory names and structure. For example, if we have a 'training' directory containing 'horses' directory and a 'humans' one. The Image Data Generator will label the images 'horses' and 'humans'.

```python
from tf.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1/255)

train_generator = train_datagen.flow_from_directory(
                    './path/',
                    target_size = (256,256), # images are resized to specified size
                    batch_size = 32,         # size of 
                    class_mode='binary')     # one of "categorical", "binary", "sparse", "input"
)
```

Training will be performed on the `train_generator` object by passing it to the `model.fit()`.

## Visualizing Intermediate Representation

To get a feel for what kind of features our CNN has learned, one fun thing to do is to visualize how an input gets transfromed as it goes through the model. 

We can pick a random image from the training set, and then generate a figure where each row is the output of a layer, and each image in the row is a specific filter in that output feature map. Return this cell to generate intermediate representations of a variety of training images.

The representations downstream start highlighting what the network pays attention to, and they show fewer and fewer features being 'activated'; most are set to zero. This is called representation sparsity and is a key feature of deep learning. These representations carry increasingly less information about the original pixels of the image, but increasingly refined information about the class of the image. 

## Data Augmentation

Data augmentation increases the amount of training data by modifiying the existing training data's properties. For example, in image data, we can apply different preprocessing techniques such as rotate, flip, shrear or zoom on the existing image. This way the model would see more variety in the images during training so it will infer better on new, previously unseed data. 

```python
train_datagen = ImageDataGenerator(
                                   rotation_range=20,      # integer range in degrees
                                   width_shift_range=0.2,  # Float, 1-D array-like or int
                                   height_shift_range=0.2, # Float, 1-D array-like or int
                                   shear_range=20,         # Shear angle in counter-clockwise direction in degrees
                                   zoom_range=[0.5, 2],    # Float or [lower, upper], Range for random zoom
                                   horiontal_flip=True     # Boolean, Randomly flip inputs horizontally
                                   vertical_flip=True      # Boolean, Randomly flip inputs vertically
                                   fill_mode='constant')   # "constant", "nearest", "reflect" or "wrap"       
                                   )
```

## Transfer Learning 

In transfer learning we use pre-trained model to achieve a good results even with a small training dataset. It leverages the trained layers of an existing model and adding it to our own layers to fit our needs.

During transfer learning, we first load a pre-trained model (e.g. InceptionV3) with appropriate input_shape and apply saved weights on it. Then we freeze its layers to stop them from getting retrained on our data by setting `layer.trainable` parameter to false.

Then we select the output 

```python
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensoflow.keras import layers

local_weight_file = './path/to/the/downloaded/weights'

pre_trained_model = InceptionV3(input_shape= (),
                                include_top=False,   # Whether to include the 
                                weights=None)

pre_trained_model.load_weights(local_weight_file)

for layer in pre_trained_model.layers:
    layer.trainable = False
    
```

Now we can pick an output layer from the pre trained model and then append our neural network to it.

```python
# Choose `mixed_7` as the last layer of your base model
last_layer = pre_trained_model.get_layer('mixed7')
last_output = last_layer.output

#Now create our neural network
x = layers.Dense(1024, activation='relu')(last_output)
x = layers.Dense(1, activation='sigmoid')(x)

# Append the dense network to the base model through outputs
model = Model(pre_trained_model.input, x)

```